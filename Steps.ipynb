{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Gibbs.GibbsSampler import GibbsSampler\n",
    "from Gibbs.Parameters import *\n",
    "from DataGeneration import generate_multiple_series\n",
    "import Gibbs.Initialize as Initialize\n",
    "import Gibbs.Priors as Priors\n",
    "import numpy as np\n",
    "from Trends import Regressors\n",
    "from Trends import LowFrequencyTrends\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load data and populations weights for the Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights: 1.0\n",
      "Dimensions of R_hat: (150, 32)\n"
     ]
    }
   ],
   "source": [
    "data = generate_multiple_series(150, 120, 10**4, 10**5, \"gibbs_data.csv\")\n",
    "q = 16\n",
    "q_hat = 31\n",
    "n = len(data)\n",
    "m = 25\n",
    "l = 10\n",
    "T = len(data[0])\n",
    "w = np.random.random(n)\n",
    "R_hat = Regressors.find_regressors(T, q_hat).T\n",
    "# Normalize the weights to sum to 1\n",
    "w = w/np.sum(w)\n",
    "print('Sum of weights: '+str(np.sum(w)))\n",
    "print('Dimensions of R_hat: '+str(R_hat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Gibbs Sampler\n",
    "\n",
    "### Step-by-step initialization\n",
    "\n",
    "Initialize $X_i$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Entries in X_i: 120\n",
      "Length of each coefficient vector: 32\n"
     ]
    }
   ],
   "source": [
    "X_i = Initialize.initialize_X(data, q)\n",
    "print(\"# Entries in X_i: \"+str(len(X_i)))\n",
    "print(\"Length of each coefficient vector: \"+str(len(X_i[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize $(F, S_m)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of F: 32\n"
     ]
    }
   ],
   "source": [
    "F = Initialize.initialize_F(X_i, w, q_hat)\n",
    "print(\"Length of F: \"+str(len(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of S_m: 32\n"
     ]
    }
   ],
   "source": [
    "S_m, sigma_m, Sigma_m = Initialize.initialize_S_m(T, R_hat)\n",
    "print(\"Length of S_m: \"+str(len(S_m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize $\\{K(j)\\}_{j=1}^{25}$ and $\\{J(i)\\}_{i=1}^n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K has 25 factors\n",
      "J has 120 factors\n"
     ]
    }
   ],
   "source": [
    "K = Priors.group_factors(m, l)\n",
    "J = Priors.group_factors(n, m) \n",
    "print(\"K has \"+str(len(K))+\" factors\")\n",
    "print(\"J has \"+str(len(J))+\" factors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalize $\\{\\lambda_{c,i}\\}_{i=1}^n$ and $\\{\\lambda_{g,j}\\}_{j=1}^{25}$ parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 120 lambda_c_i parameters\n",
      "We have 25 lambda_g_j parameters\n"
     ]
    }
   ],
   "source": [
    "lambdas = Lambda_Parameters(n, m)\n",
    "print(\"We have \"+ str(len(lambdas.lambda_c_i))+\" lambda_c_i parameters\")\n",
    "print(\"We have \"+ str(len(lambdas.lambda_g_j))+\" lambda_g_j parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalize $\\{\\kappa_{c,i}\\}_{i=1}^n$, $\\{\\kappa_{g,j}\\}_{j=1}^{25}$ \n",
    "and $\\{\\kappa_{h,k}\\}_{k=1}^{10}$ parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 120 kappa_c_i parameters\n",
      "We have 25 kappa_g_j parameters\n",
      "We have 10 kappa_h_k parameters\n"
     ]
    }
   ],
   "source": [
    "kappas = Kappa_Parameters(n,m,l)\n",
    "print(\"We have \"+ str(len(kappas.kappa_c_i))+\" kappa_c_i parameters\")\n",
    "print(\"We have \"+ str(len(kappas.kappa_g_j))+\" kappa_g_j parameters\")\n",
    "print(\"We have \"+ str(len(kappas.kappa_h_k))+\" kappa_h_k parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all $p$ parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 25 p_c_l parameters\n",
      "We have 25 p_g_l parameters\n",
      "We have 100 p_c_theta parameters\n",
      "We have 100 p_g_theta parameters\n",
      "We have 100 p_h_theta parameters\n",
      "We have 25 p_c_k parameters\n",
      "We have 25 p_g_k parameters\n",
      "We have 25 p_h_k parameters\n"
     ]
    }
   ],
   "source": [
    "p_parameters = P_Parameters()\n",
    "print(\"We have \"+ str(len(p_parameters.p_c_lambda))+\" p_c_l parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_g_lambda))+\" p_g_l parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_c_theta))+\" p_c_theta parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_g_theta))+\" p_g_theta parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_h_theta))+\" p_h_theta parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_c_kappa))+\" p_c_k parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_g_kappa))+\" p_g_k parameters\")\n",
    "print(\"We have \"+ str(len(p_parameters.p_h_k))+\" p_h_k parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize $\\sigma_{\\Delta a}^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_Da = 4.250042500425004\n"
     ]
    }
   ],
   "source": [
    "s_Da = Initialize.inverse_squared(0.03**2)\n",
    "print(\"s_Da = \"+str(s_Da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize $f_0$, $\\mu_m$ and $\\mu_c$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_0 = 561651.4730103255\n",
      "mu_m = 738791.691688194\n",
      "mu_c = 967073.662156095\n"
     ]
    }
   ],
   "source": [
    "f_0 = Priors.flat_prior(0, 10**6)\n",
    "mu_m = Priors.flat_prior(0, 10**6)\n",
    "mu_c = Priors.flat_prior(0, 10**6)\n",
    "print(\"f_0 = \"+str(f_0))\n",
    "print(\"mu_m = \"+str(mu_m))\n",
    "print(\"mu_c = \"+str(mu_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize $\\omega^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega_squared = 61.230612306123064\n"
     ]
    }
   ],
   "source": [
    "omega_squared = Initialize.inverse_squared(1)\n",
    "print(\"omega_squared = \" + str(omega_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize $U_{c,i}$, $U_{g,j}$ and $U_{h,k}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\konto\\Documents\\Economy-and-Population-Growth\\Gibbs\\Priors.py:78: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  return np.random.multivariate_normal(mean=mean, cov=cov, size=n)\n"
     ]
    }
   ],
   "source": [
    "us = U_Parameters(omega_squared, lambdas, kappas, R_hat, n, m, l, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "32\n",
      "25\n",
      "32\n",
      "10\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(us.U_c))\n",
    "print(len(us.U_c[0]))\n",
    "print(len(us.U_g))\n",
    "print(len(us.U_g[0]))\n",
    "print(len(us.H))\n",
    "print(len(us.H[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "G = []\n",
    "for j in range(m):\n",
    "    G_j = lambdas.lambda_g_j[j]*us.H[K[j]]+us.U_g[j]\n",
    "    G.append(G_j)\n",
    "\n",
    "C = []\n",
    "i_1 = np.zeros(q_hat+1)\n",
    "i_1[0] = 1\n",
    "for i in range(n):\n",
    "    C_i = mu_c*i_1+lambdas.lambda_c_i[i]*G[J[i]]+us.U_c[i]\n",
    "    C.append(C_i)\n",
    "G = np.array(G)\n",
    "C = np.array(C)\n",
    "print(len(G))\n",
    "print(len(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of a Gibbs Draw\n",
    "\n",
    "### Step 1: Calculate $\\{X_i\\}_{i=1}^n$\n",
    "\n",
    "Calculate $Y^0$, $\\mu_C$, $\\Sigma$, $\\Beta$, $w$, $m$ and $V$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = w@C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_1 = np.zeros(q_hat+1)\n",
    "i_1[0] = 1\n",
    "mu_C = np.concatenate([mu_c*i_1.T+lambdas.lambda_c_i[i]*G[J[i]].T for i in range(n)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (q_hat+1)*n\n",
    "Sigma = np.zeros((dim, dim))\n",
    "Sigma[0:(q_hat+1), 0:(q_hat+1)] = us.S_U_c[0]\n",
    "for i in range(n):\n",
    "    Sigma[i*(q_hat+1):(i+1)*(q_hat+1), i*(q_hat+1):(i+1)*(q_hat+1)] = us.S_U_c[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 2040)\n"
     ]
    }
   ],
   "source": [
    "# X = np.concatenate([X_i[i].T for i in range(n)]).T\n",
    "# X = np.reshape(X_i, (dim, ))\n",
    "X = X_i.flatten()\n",
    "Ys = []\n",
    "for i in range(n):\n",
    "    Y_i, _ = LowFrequencyTrends.find_trends(data[i], q)\n",
    "    Ys.append(Y_i)\n",
    "\n",
    "Y = np.concatenate([Ys[i] for i in range(len(Ys))])\n",
    "\n",
    "def find_B(A, C):\n",
    "    a = len(A)\n",
    "    c = len(C)\n",
    "    B = np.zeros((a, c))\n",
    "    for i in range(a):\n",
    "        B[i, :] = A[i]*C\n",
    "    return B.T\n",
    "\n",
    "B = find_B(Y, X)\n",
    "I = np.identity(q_hat+1)\n",
    "ws = np.kron(w.T, I).T\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.concatenate([C[i] for i in range(len(C))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "help = Sigma@B\n",
    "mm = help@np.linalg.inv(B.T@help)@B.T@(Cs-mu_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 3840)\n"
     ]
    }
   ],
   "source": [
    "V = Sigma-help@np.linalg.inv(B.T@help)@B.T@Sigma\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.04397305e+02, -8.13758095e-01, -5.17805601e+02, ...,\n",
       "         3.71673044e-02, -5.63409197e+00, -3.24447641e-02],\n",
       "       [-4.13548496e-01, -3.22353566e-03, -2.05118060e+00, ...,\n",
       "         1.47230647e-04, -2.23182989e-02, -1.28523273e-04],\n",
       "       [-1.84045745e+02, -1.43460327e+00, -9.12858023e+02, ...,\n",
       "         6.55235709e-02, -9.93254236e+00, -5.71980357e-02],\n",
       "       ...,\n",
       "       [ 2.04286176e-02,  1.59237376e-04,  1.01324958e-01, ...,\n",
       "        -7.27295255e-06,  1.10248737e-03,  6.34883896e-06],\n",
       "       [-3.16772362e+00, -2.46918321e-02, -1.57117564e+01, ...,\n",
       "         1.12776616e-03, -1.70955047e-01, -9.84470292e-04],\n",
       "       [-2.60707521e-02, -2.03216793e-04, -1.29309673e-01, ...,\n",
       "         9.28165315e-06, -1.40698090e-03, -8.10231068e-06]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help@np.linalg.inv(B.T@help)@B.T@Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv1 = np.linalg.inv(B.T@help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.from_numpy(B.T@help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv2 = torch.inverse(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    B = torch.tensor(B, device=device)\n",
    "    help = torch.tensor(help, device=device)\n",
    "    Sigma = torch.tensor(Sigma, device=device)\n",
    "    inv2 = torch.inverse(torch.matmul(B.t(), help))\n",
    "    mat = torch.chain_matmul(help, inv2, B.t(), Sigma)\n",
    "    result = torch.inverse(mat)\n",
    "    result = result.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw $Z_0$, calculate $Z_1$, draw $\\epsilon$ and caclulate $C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0 = Priors.multivariate_normal_prior(mu_C, V/np.linalg.norm(V))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "normal_V = V/np.linalg.norm(V)\n",
    "mu_C = torch.tensor(mu_C, device=device)\n",
    "normal_V = torch.tensor(normal_V, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positive_definite(matrix, epsilon=1e-6):\n",
    "    # Eigenvalue decomposition\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(matrix, UPLO='U')  # 'U' for upper triangular part\n",
    "    # Clip eigenvalues to ensure they are positive or greater than epsilon\n",
    "    clipped_eigenvalues = torch.clamp(eigenvalues, min=epsilon)\n",
    "    # Reconstruct the matrix with modified eigenvalues\n",
    "    modified_matrix = eigenvectors @ torch.diag(clipped_eigenvalues) @ eigenvectors.T\n",
    "    return modified_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_V = make_positive_definite(normal_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.distributions.MultivariateNormal(mu_C, modified_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0 = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840\n"
     ]
    }
   ],
   "source": [
    "print(Z0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_independent_samples(mean, covariance, num_blocks, num_samples=1):\n",
    "    # Get the size of each block\n",
    "    block_size = mean.shape[0] // num_blocks\n",
    "    \n",
    "    # Reshape the mean vector to have shape (num_blocks, block_size)\n",
    "    mean = mean.view(num_blocks, block_size)\n",
    "    \n",
    "    # Draw independent samples for each block\n",
    "    samples = []\n",
    "    for i in range(num_blocks):\n",
    "        block_mean = mean[i]  # Extract mean for each block\n",
    "        block_covariance = make_positive_definite(covariance[i * block_size : (i + 1) * block_size, i * block_size : (i + 1) * block_size])\n",
    "        \n",
    "        # Create a MultivariateNormal distribution for the block\n",
    "        mvn_distribution = torch.distributions.MultivariateNormal(block_mean, block_covariance)\n",
    "        \n",
    "        # Draw samples from the distribution\n",
    "        block_samples = mvn_distribution.sample((num_samples,))\n",
    "        samples.append(block_samples)\n",
    "    \n",
    "    # Stack the samples along the last dimension\n",
    "    samples = torch.cat(samples, dim=1)\n",
    "    \n",
    "    return samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.6707e+05,  9.0367e-02, -7.6190e+01,  ..., -1.9676e+00,\n",
      "        -9.4575e+00,  1.9471e+01], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "Z = draw_independent_samples(mu_C, normal_V, n)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840,)\n"
     ]
    }
   ],
   "source": [
    "Z1 = Z0-help@np.linalg.inv(B.T@help)@B.T@(Z0-Cs)\n",
    "print(Z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = np.identity(q_hat+1)*0.01**2\n",
    "epsilon = Priors.multivariate_normal_prior(Y0, Delta)[0]\n",
    "e = np.repeat(epsilon, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840,)\n",
      "(120, 32)\n",
      "(120, 32)\n",
      "(120, 32)\n"
     ]
    }
   ],
   "source": [
    "Cs = Z1 - V@ws@(ws.T@V@ws+Delta)@ws.T@(Z1-e)\n",
    "print(Cs.shape)\n",
    "CC = np.reshape(Cs, (n, q_hat+1))\n",
    "print(CC.shape)\n",
    "XX = CC+F\n",
    "print(X_i.shape)\n",
    "print(XX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate $(F, S_m)$:\n",
    "\n",
    "Calculate $\\mu_F$ and $\\Sigma_F$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "i_2 = np.zeros(q_hat+1)\n",
    "i_2[1] = 1\n",
    "\n",
    "mu_F = i_1*f_0+i_2*mu_m\n",
    "print(mu_F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "A, Sigma_A = Initialize.init_Sigma_A(R_hat, T, q_hat, s_Da)\n",
    "Sigma_F = sigma_m**3*Sigma_m+s_Da**2*Sigma_A\n",
    "print(Sigma_F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $e$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 32)\n"
     ]
    }
   ],
   "source": [
    "e = np.kron(np.ones(n).T, I).T\n",
    "print(e.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $m_F$, $V_F$, and draw $F-\\mu_F$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "V_F = np.linalg.inv(np.linalg.inv(Sigma_F)+e.T@np.linalg.inv(Sigma)@e+np.linalg.inv(Delta))\n",
    "print(V_F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m_F \u001b[38;5;241m=\u001b[39m V_F\u001b[38;5;241m@\u001b[39m(e\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(Sigma)\u001b[38;5;241m@\u001b[39m(\u001b[43mX\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmu_C\u001b[49m\u001b[38;5;241m-\u001b[39me\u001b[38;5;129m@mu_F\u001b[39m)\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(Delta)\u001b[38;5;241m@\u001b[39m((ws\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@X\u001b[39m)\u001b[38;5;241m-\u001b[39mY0\u001b[38;5;241m-\u001b[39mmu_F))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(m_F\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "m_F = V_F@(e.T@np.linalg.inv(Sigma)@(X-mu_C-e@mu_F)+np.linalg.inv(Delta)@((ws.T@X)-Y0-mu_F))\n",
    "print(m_F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "draw = Priors.multivariate_normal_prior(m_F, V_F)[0]\n",
    "FF = draw+mu_F\n",
    "print(FF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\Sigma_S$ and draw $S_m$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "Sigma_S = sigma_m**2*Sigma_m\n",
    "print(Sigma_S.shape)\n",
    "mean_S_m = Sigma_S@np.linalg.inv(Sigma_F)@(FF-mu_F)\n",
    "var_S_m = Sigma_S-Sigma_S@np.linalg.inv(Sigma_F)@Sigma_S\n",
    "\n",
    "SS_m = Priors.multivariate_normal_prior(mean_S_m, var_S_m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
